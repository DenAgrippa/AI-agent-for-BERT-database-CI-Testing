
# Проект c ИИ-агентом: Классификация и обработка промптов с Llama и BERT

## Описание проекта
Этот проект представляет собой систему для защиты с использованием модели BERT и генерации ответа с помощью Llama-3.2-1B (unsloth).

Основные задачи проекта:
1. Классификация промпта на "Regular" и "Jailbreak" с помощью модели BERT.
2. Сохранение промптов и их меток в базе данных SQLite.
3. Генерация ответа на промпт, если он классифицирован как "Regular", с использованием Llama-3 через библиотеку LangChain.

LangChain используется для стандартизации интерфейса нашей модели и будущей интеграции с более сложными цепочками (chains) и агентами. В нашем коде:

Мы импортируем базовый класс LLM из langchain.llms.base.

Наш класс LlamaLLM наследуется от этого класса, что делает его совместимым с LangChain.

Это означает, что даже если сейчас мы просто вызываем нашу модель через llm(prompt), в будущем мы можем легко интегрировать её в более сложные цепочки, добавлять память, инструменты или другие шаги обработки, используя все возможности LangChain. Таким образом, библиотека LangChain служит фундаментом для создания гибких и расширяемых агентов на основе LLM.

---
## Структура проекта
```
├── agent.py         # Главный файл для запуска проекта
├── bert_filter.py   # Классификатор промптов с помощью BERT
├── database.py      # Управление SQLite базой данных
├── prompts.db       # Файл с созданной базой данных
├── requirements.txt # Файл с необходимыми библиотеками
├── README.md        # Описание проекта
```

---
## Установка и настройка
### Установка зависимостей
Перед запуском необходимо установить все зависимости:
```bash
pip install torch torchvision transformers unsloth langchain
```
---
## Запуск проекта
Запуск проекта осуществляется командой:
```bash
python agent.py
```
После запуска скрипт попросит ввести промпт, классифицирует его и, если промпт допустим, сгенерирует ответ с помощью Llama.

---
## Как это работает?
### 1. Классификация промпта (bert_filter.py)
- Использует предобученную BERT-модель для классификации.
- Выдаёт `0` для обычных промптов и `1` для вредоносных (jailbreak).

### 2. Сохранение в базу данных (database.py)
- SQLite база данных хранит промпты, их метки и временные метки.

### 3. Генерация ответа (agent.py)
- Если промпт допустим, вызывается модель Llama-3 через библиотеку LangChain.
- Llama-3 отвечает на промпт и возвращает результат пользователю.

---
## Заключение
Этот проект позволяет автоматически фильтровать вредоносные промпты перед их обработкой моделью Llama. Он может использоваться в чат-ботах, онлайн-сервисах или исследованиях в области обработки естественного языка.
# front-end

